{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "739ddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ac6e1",
   "metadata": {},
   "source": [
    "## Model For Determining if Fingerprint is real or moulded....?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f81a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 96, 96, 20)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 48, 48, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 48, 48, 40)        7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 24, 24, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 24, 24, 60)        21660     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 12, 12, 80)        43280     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 11520)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1000)              11521000  \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,693,682\n",
      "Trainable params: 11,693,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(20,(3,3), padding='same',activation='relu',input_shape=(96,96,1)))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(40,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Conv2D(60,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D((2,2))) \n",
    "model.add(Conv2D(80,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cd8ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ff588",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "053d303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "344f3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5bdbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0ad672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "\n",
    "    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "   \n",
    "    train_data = np.array(img_resize).reshape(-1, img_size, img_size, 1)\n",
    "    train_data = train_data / 255.0\n",
    "                               \n",
    "\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "439210a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 96, 96, 20)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 96, 96, 40)        7240      \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 96, 96, 60)        21660     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 96, 96, 80)        43280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 48, 48, 80)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 184320)            0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               18432100  \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 18,505,512\n",
      "Trainable params: 18,505,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender = Sequential()\n",
    "\n",
    "model_gender.add(Conv2D(filters = 20, kernel_size = (3,3),padding = 'Same',activation ='relu',input_shape = (96,96,1)))\n",
    "model_gender.add(Conv2D(filters = 40, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model_gender.add(Conv2D(filters = 60, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model_gender.add(Conv2D(filters = 80, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "\n",
    "model_gender.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# model_gender.add(Dropout(0.25))\n",
    "# model_gender.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "# model_gender.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "# model_gender.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "# model_gender.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model_gender.add(Flatten())\n",
    "model_gender.add(Dense(100, activation = \"relu\"))\n",
    "model_gender.add(Dense(10, activation = \"relu\"))\n",
    "# model_gender.add(Dense(2, activation = \"tanh\"))\n",
    "model_gender.add(Dense(2,activation='softmax'))\n",
    "# model_gender.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc203170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.load_weights(\"model_gender (1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02c480b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "24035e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_gender(img_path):\n",
    "    new_image = load_image(img_path)\n",
    "    pred = model.predict(new_image)\n",
    "    labels = np.array(pred)\n",
    "    if(labels[0][0]>labels[0][1]):\n",
    "        print(\"Male\")\n",
    "        s = \"Fingerprint may be of Male ðŸ‘¨\"\n",
    "    else:\n",
    "        print(\"Female\")\n",
    "        s = \"Fingerprint may be of Female ðŸ‘§\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b1588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62de91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path):\n",
    "    new_image = load_image(img_path)\n",
    "    \n",
    "    pred = model.predict(new_image)\n",
    "    labels = np.array(pred)\n",
    "    if(labels[0][0]>labels[0][1]):\n",
    "        print(\"Altered Image\")\n",
    "        s = \"ALERT !!! THIS IS AN ALTERED IMAGE ðŸ˜µ\" \n",
    "    else:\n",
    "        print(\"Real Image\")\n",
    "        s = \"NO Worries !!! It's a Real Image ðŸ™‚\"\n",
    "    # p=model.predict_clasess(pred)\n",
    "    # print(p)\n",
    "    # print(labels)\n",
    "    # print(labels[0][0])\n",
    "    # print(pred)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1f7ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4404b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2e5ddd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/predict\", methods = ['GET','POST'])\n",
    "\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file_1']\n",
    "        filename = file.filename\n",
    "        file_path = os.path.join('static/', filename)                       \n",
    "        file.save(file_path)\n",
    "        print(filename)\n",
    "        product = prediction(file_path)\n",
    "        print(product)\n",
    "        \n",
    "    return render_template('predict.html', product = product, user_image = file_path)            \n",
    "\n",
    "@app.route(\"/gender\", methods = ['GET','POST'])\n",
    "\n",
    "def gender():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file_2']\n",
    "        filename = file.filename\n",
    "        file_path = os.path.join('static/', filename)                      \n",
    "        file.save(file_path)\n",
    "        print(filename)\n",
    "        product = prediction_gender(file_path)\n",
    "        print(product)\n",
    "        \n",
    "    return render_template('predict.html', product = product, user_image = file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a9f3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Dec/2021 19:57:11] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6__M_Left_middle_finger (1).BMP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Dec/2021 19:58:02] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Image\n",
      "NO Worries !!! It's a Real Image ðŸ™‚\n",
      "a1.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Dec/2021 19:59:27] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altered Image\n",
      "ALERT !!! THIS IS AN ALTERED IMAGE ðŸ˜µ\n",
      "r1.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Dec/2021 19:59:51] \"\u001b[37mPOST /gender HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n",
      "Fingerprint may be of Female ðŸ‘§\n",
      "a1.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Dec/2021 20:00:23] \"\u001b[37mPOST /gender HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n",
      "Fingerprint may be of Male ðŸ‘¨\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction('a1.jpeg')\n",
    "# #altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834745f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction('r1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7446fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction('2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f692d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction(r'C:\\Users\\Shantanu Goyal\\Desktop\\Flask\\Defect-Detection-of-PCB-main\\102__M_Right_little_finger_Zcut.BMP')\n",
    "# altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction(r'C:\\Users\\Shantanu Goyal\\Desktop\\Flask\\103__F_Left_middle_finger_CR.BMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b83b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction(r'C:\\Users\\Shantanu Goyal\\Desktop\\Flask\\100__M_Right_ring_finger_CR.BMP'))                                #significance of r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product = prediction(r'C:\\Users\\nEW u\\Flask\\Dataset\\test\\test5\\bad (25)k.jpeg')                                                                        #it will accept image directly if both .ipynb and image lie on same place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f5053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4614130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0e414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deda86ea4ce6d86b4986790dadf2efba8cb167ef81aacab33b06cf5148ebc177"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
